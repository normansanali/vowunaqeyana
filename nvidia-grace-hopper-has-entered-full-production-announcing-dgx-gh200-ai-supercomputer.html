<!doctype html><html class=no-js lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Grace Hopper Has Entered Full Production &amp;amp; Announcing DGX GH200 AI Supercomputer - JadeZ</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content="Teeing off an AI-heavy slate of announcements for NVIDIA, the company has confirmed that their Grace Hopper superchip has entered full production. The combination of a Grace CPU and Hopper H100 GPU, Grace Hopper is designed to be NVIDIAs answer for customers who need a more tightly integrated CPU + GPU solution for their workloads"><meta name=robots content="index,follow,noarchive"><meta property="og:title" content="Grace Hopper Has Entered Full Production &amp;amp; Announcing DGX GH200 AI Supercomputer"><meta property="og:description" content="Teeing off an AI-heavy slate of announcements for NVIDIA, the company has confirmed that their Grace Hopper superchip has entered full production. The combination of a Grace CPU and Hopper H100 GPU, Grace Hopper is designed to be NVIDIAs answer for customers who need a more tightly integrated CPU + GPU solution for their workloads"><meta property="og:type" content="article"><meta property="og:url" content="/nvidia-grace-hopper-has-entered-full-production-announcing-dgx-gh200-ai-supercomputer.html"><meta property="article:section" content="post"><meta property="article:published_time" content="2024-09-12T00:00:00+00:00"><meta property="article:modified_time" content="2024-09-12T00:00:00+00:00"><meta itemprop=name content="Grace Hopper Has Entered Full Production &amp;amp; Announcing DGX GH200 AI Supercomputer"><meta itemprop=description content="Teeing off an AI-heavy slate of announcements for NVIDIA, the company has confirmed that their Grace Hopper superchip has entered full production. The combination of a Grace CPU and Hopper H100 GPU, Grace Hopper is designed to be NVIDIAs answer for customers who need a more tightly integrated CPU + GPU solution for their workloads"><meta itemprop=datePublished content="2024-09-12T00:00:00+00:00"><meta itemprop=dateModified content="2024-09-12T00:00:00+00:00"><meta itemprop=wordCount content="1350"><meta itemprop=keywords content><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=https://assets.cdnweb.info/hugo/mainroad/css/style.css><link rel="shortcut icon" href=./favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=./index.html title=JadeZ rel=home><div class="logo__item logo__text"><div class=logo__title>JadeZ</div></div></a></div><div class=divider></div></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>Grace Hopper Has Entered Full Production &amp;amp; Announcing DGX GH200 AI Supercomputer</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2024-09-12T00:00:00Z>September 12, 2024</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=./categories/blog/ rel=category>blog</a></span></div></div></header><div class="content post__content clearfix"><p>Teeing off an AI-heavy slate of announcements for NVIDIA, the company has confirmed that their Grace Hopper “superchip” has entered full production. The combination of a Grace CPU and Hopper H100 GPU, Grace Hopper is designed to be NVIDIA’s answer for customers who need a more tightly integrated CPU + GPU solution for their workloads – particularly for AI models.</p><p>In the works for a few years now, Grace Hopper is NVIDIA’s efforts to leverage both their existing strength in the GPU space and newfound efforts in the CPU space to deliver a semi-integrated CPU/GPU product unlike anything their top-line competitors offer. With NVIDIA’s traditional dominance in the GPU space, the company has essentially been working backwards, combining their GPU technology with other types of processors (CPUs, DPUs, etc) in order to access markets that benefit from GPU acceleration, but where fully discrete GPUs may not be the best solution.</p><table align=center border=1 cellpadding=3 cellspacing=0 width=550><tbody readability=1><tr class=tgrey readability=2><td align=center colspan=4>NVIDIA Grace Hopper Specifications</td></tr><tr class=tlblue><td align=center class=contentwhite width=243>&nbsp;</td><td align=center class=contentwhite width=389>Grace Hopper (GH200)</td></tr><tr><td align=left class=tlgrey><strong>CPU Cores</strong></td><td align=center>72</td></tr><tr><td align=left class=tlgrey><strong>CPU Architecture</strong></td><td align=center>Arm Neoverse V2</td></tr><tr><td align=left class=tlgrey><strong>CPU Memory Capacity</strong></td><td align=center>&lt;=480GB LPDDR5X (ECC)</td></tr><tr><td align=left class=tlgrey><strong>CPU Memory Bandwidth</strong></td><td align=center>&lt;=512GB/sec</td></tr><tr><td align=left class=tlgrey><strong>GPU SMs</strong></td><td align=center>132</td></tr><tr><td align=left class=tlgrey><strong>GPU Tensor Cores</strong></td><td align=center>528</td></tr><tr><td align=left class=tlgrey><strong>GPU Architecture</strong></td><td align=center>Hopper</td></tr><tr><td align=left class=tlgrey><strong>GPU Memory Capcity</strong></td><td align=center>&lt;=96GB</td></tr><tr><td align=left class=tlgrey><strong>GPU Memory Bandwidth</strong></td><td align=center>&lt;=4TB/sec</td></tr><tr><td align=left class=tlgrey><strong>GPU-to-CPU Interface</strong></td><td align=center>900GB/sec<br>NVLink 4</td></tr><tr><td align=left class=tlgrey><strong>TDP</strong></td><td align=center>450W - 1000W</td></tr><tr><td align=left class=tlgrey><strong>Manufacturing Process</strong></td><td align=center>TSMC 4N</td></tr><tr><td align=left class=tlgrey><strong>Interface</strong></td><td align=center>Superchip</td></tr></tbody></table><p>In this first NVIDIA HPC CPU + GPU mash-up, the Hopper GPU is the known side of the equation. While it only started shipping in appreciable volumes this year, NVIDIA was <a href=#>detailing the Hopper architecture and performance expectations over a year ago</a>. Based on the 80B transistor GH100 GPU, H100 brings just shy of 1 PFLOPS of FP16 matrix math throughput for AI workloads, as well as 80GB of HBM3 memory. H100 is itself already a huge success – thanks to the explosion of ChatGPT and other generative AI services, NVIDIA is already selling everything they can make – but NVIDIA is still pushing ahead with their efforts to break into markets where the workloads require closer CPU/GPU integration.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/18877/nvidia-grace-hopper-superchip_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>Being paired with H100, in turn, is NVIDIA’s <a href=#>Grace CPU</a>, which itself just entered full production a couple of months ago. The Arm Neoverse V2-based chip packs 72 CPU cores, and comes with up to 480GB of LPDDR5X memory. And while the CPU cores are themselves plenty interesting, the bigger twist with Grace has been NVIDIA’s decision to co-package the CPU with LPDDR5X, rather than using slotted DIMMs. The on-package memory has allowed NVIDIA to use both higher clocked and lower power memory – at the cost of expandability – which makes Grace unlike any other HPC-class CPU on the market. And potentially a very big deal for Large Language Model (LLM) training, given the emphasis on both dataset sizes and the memory bandwidth needed to shuffle that data around.</p><p>It’s that data shuffling, in turn, that helps to define a single Grace Hopper board as something more than just a CPU and GPU glued together on the same board. Because NVIDIA equipped Grace with NVLink support – NVIDIA’s proprietary high-bandwidth chip interconnect – Grace and Hopper have a much faster interconnect than a traditional, PCIe-based CPU + GPU setup. The resulting NVLink Chip-to-Chip (C2C) link offers 900GB/second of bandwidth between the two chips (450GB/sec in each direction), giving Hopper the ability to talk back to Grace even faster than Grace can read or write to its own memory.</p><p>The resulting board, which NVIDIA calls their GH200 “superchip”, is meant to be NVIDIA’s answer to the AI and HPC markets for the next product cycle. For customers who need a more local CPU than a traditional CPU + GPU setup – or perhaps more pointedly, more quasi-local memory than a stand-alone GPU can be equipped with – Grace Hopper is NVIDIA’s most comprehensive compute product yet. Meanwhile, with there being some uncertainty over just how prevalent the Grace-only (CPU-only) superchip will be, given that NVIDIA is currently on an AI bender, Grace Hopper may very well end up being where we see the most of Grace, as well.</p><p>According to NVIDIA, systems incorporating GH200 chips are slated to be available later this year.</p><h2>DGX GH200 AI Supercomputer: Grace Hopper Goes Straight To the Big Leagues</h2><p>Meanwhile, even though Grace Hopper is not technically out the door yet, NVIDIA is already at work building its first DGX system around the chip. Though in this case, “DGX” may be a bit of a misnomer for the system, which unlike other DGX systems isn’t a single node, but rather a full-on multi-rack computational cluster – hence NVIDIA terming it a “supercomputer.”</p><p>At a high level, the DGX GH200 AI Supercomputer is a complete, turn-key, 256 node GH200 cluster. Spanning some 24 racks, a single DGX GH200 contains 256 GH200 chips – and thus, 256 Grace CPUs and 256 H100 GPUs – as well as all of the networking hardware needed to interlink the systems for operation. In cumulative total, a DGX GH200 cluster offers 120TB of CPU-attached memory, another 24TB of GPU-attached memory, and a total of 1 EFLOPS of FP8 throughput (with sparsity).</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/18877/nvidia-dgx-gh200_575px.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a><br>Look Closer: That's Not a Server Node - That's 24 Server Racks</p><p>Linking the nodes together is a two-layer networking system built around NVLink. 96 local, L1 switches provide immediate communications between the GH200 blades, while another 36 L2 switches provide a second layer of connectivity tying together the L1 switches. And if that’s not enough scalability for you, DGX GH200 clusters can be further scaled up in size by using InfiniBand, which is present in the cluster as part of NVIDIA’s use of ConnectX-7 network adapters.</p><p align=center><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/18877/diagram-topology-nvlink-switch-system-dgx-gh200_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>The target market for the sizable silicon cluster is training large AI models. NVIDIA is leaning heavily on their existing hardware and toolsets in the field, combined with the sheer amount of memory and memory bandwidth a 256-node cluster affords to be able to accommodate some of the largest AI models around. The recent explosion in interest in large language models has exposed just how much memory capacity is a constraining factor, so this is NVIDIA’s attempt to offer a single-vendor, integrated solution for customers with especially large models.</p><p>And while not explicitly disclosed by NVIDIA, in a sign that they all pulling out all of the stops for the DGX GH200 cluster, the memory capacities they’ve listed indicate that NVIDIA isn’t just shipping regular H100 GPUs as part of the system, but rather they are using their limited availability 96GB models, which have the normally-disabled 6th stack of HBM3 memory enabled. So far, NVIDIA only offers these H100 variants in a handful of products – the specialty <a href=#>H100 NVL PCIe card</a> and now in some GH200 configurations – so DGX GH200 is slated to get some of NVIDIA’s best silicon.</p><p>Of course, don’t expect a supercomputer from NVIDIA to come cheaply. While NVIDIA is not announcing any pricing this far in advance, based on HGX H100 board pricing (8x H100s on a carrier board for $200K), a single DGX GH200 is easily going to cost somewhere in the low 8 digits. Suffice it to say, DGX GH200 is aimed at a rather specific subset of Enterprise clientele – those who need to do a lot of large model training and have the deep pocketbooks to pay for a complete, turn-key solution.</p><p>Ultimately, however, DGX GH200 isn’t just meant to be a high-end system for NVIDIA to sell to deep-pocketed customers, but it’s the blueprint for helping their hyperscaler customers build their own GH200-based clusters. Building such a system is, after all, the best way to demonstrate how it works and how well it works, so NVIDIA is forging their own path in this regard. And while NVIDIA would no doubt be happy to sell a whole lot of these DGX systems directly, so long as it gets hyperscalers, CSPs, and others adopting GH200 in large numbers (and not, say, rival products), then that’s still going to be a win in NVIDIA’s books.</p><p>In the meantime, for the handful of businesses that can afford a DGX GH200 AI Supercomputer, according to NVIDIA the systems will be available by the end of the year.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH55hJZwZqeumZm2onnGq5icnV2dvLG8xKtkoZmjYrKvwMSrnJ1llqq5rXnPq6adrZOptrC6jJqlp6elo7CqusZmm6CwXZy1c3yPZpiiZaOqvaa%2Bwqikqa2kmr8%3D</p></div></article></main><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=./jeff-darwin.html rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>Jeff Darwin</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=./intel-iris-pro-5200-graphics-review-core-i74950hq-tested.html rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>Final Words - Intel Iris Pro 5200 Graphics Review: Core i7-4950HQ Tested</p></a></div></nav></div><aside class=sidebar><div class="widget-recent widget"><h4 class=widget__title>Recent Posts</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=./brittney-griner-height-weight-net-worth-age-birthday-wikipedia-who-nationality-biography-103530-html.html>Brittney Griner Height, Weight, Net Worth, Age, Birthday, Wikipedia, Who, Nationality, Biography</a></li><li class=widget__item><a class=widget__link href=./dekker-edward-gosselaar.html>Dekker Edward Gosselaar - Bio, Age, Single, Net Worth, Facts</a></li><li class=widget__item><a class=widget__link href=./dennis-and-trinity-rodman-a-sporting-familys-journey-as-a-soccer-superstar.html>Dennis and Trinity Rodman: A Sporting Family's Journey as a Soccer Superstar</a></li><li class=widget__item><a class=widget__link href=./erika-christensens-husband-cole-delivers-her-second-child.html>Erika Christensen's Husband Cole Delivers Her Second Child</a></li><li class=widget__item><a class=widget__link href=./401919-eva-marcilles-fans-get-emotional-and-did-html.html>Eva Marcilles Fans Get Emotional &amp;amp; Did Not Expect Her Divorce from Michael Sterling</a></li></ul></div></div><div class="widget-categories widget"><h4 class=widget__title>Categories</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=./categories/blog/>blog</a></li></ul></div></div></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2024 JadeZ.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=https://assets.cdnweb.info/hugo/mainroad/js/menu.js></script>
<script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>